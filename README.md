# ğŸ§  LLM Debate Agent

> A multi-agent reasoning system that debates complex questions, evaluates arguments, and produces more reliable, explainable AI outputs.

## ğŸ“Œ Problem Statement

Large Language Models (LLMs) often:
- Produce confident but incorrect answers
- Struggle with controversial or subjective questions
- Provide single-perspective reasoning
- Lack transparent evaluation of their own responses

For decision-making, learning, and analysis, a single LLM response is not enough.  
Users need balanced reasoning, counter-arguments, and measurable confidence.

## ğŸ’¡Solution

The **LLM Debate Agent** is a **multi-agent architecture** where multiple LLMs debate a topic from opposing perspectives, followed by an independent evaluation agent that scores and synthesizes the final answer.

Instead of asking *â€œWhat is the answer?â€*, we ask:

> â€œWhat are the strongest arguments **for**, **against**, and which one actually holds up?â€



## Architectural Summary Video : https://youtu.be/YYz59eWWCT0

## Youtube Video : https://youtu.be/-n4D94Ny4ek?si=sbvnMG049G9L5ke2

## Architecture Diagram : 
<img width="1916" height="767" alt="Screenshot 2026-02-07 170717" src="https://github.com/user-attachments/assets/6f148b1f-abd8-49fa-8f24-428fdf662a88" />

## Flow Chart : 
<img width="4000" height="1000" alt="image" src="https://github.com/user-attachments/assets/9009a5a1-dcba-4b89-a00f-2b8ccf4a0404" />
